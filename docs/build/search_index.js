var documenterSearchIndex = {"docs":
[{"location":"#HighDimMixedModels.jl","page":"Home","title":"HighDimMixedModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"HighDimMixedModels.jl is a package for fitting regularized linear mixed-effect models to high dimensional, clustered data. It is a Julia implementation of the estimation approach in","category":"page"},{"location":"","page":"Home","title":"Home","text":"Schelldorfer, J., Bühlmann, P., & DE GEER, S. V. (2011). Estimation for high‐dimensional linear mixed‐effects models using ℓ1‐penalization. Scandinavian Journal of Statistics, 38(2), 197-214.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Two options for penalties are provided, the original LASSO and the smoothly clipped absolute deviation (SCAD) penalty described in","category":"page"},{"location":"","page":"Home","title":"Home","text":"Ghosh, A., & Thoresen, M. (2018). Non-concave penalization in linear mixed-effect models and regularized selection of fixed effects. AStA Advances in Statistical Analysis, 102, 179-210.","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The cognitive dataset contains data from a study of the effect of an intervention in school lunches among schools in Kenya, accessed via the R package splmm. The data is longitudinal with measurements of students' performance on various tests taken at different points in time. We will fit a model with random intercepts and random growth slopes for each student. Note that while this is a low-dimensional example (p  n), the algorithm that this package implements was designed and tested with the high dimensional use-case (p  n) in mind.","category":"page"},{"location":"","page":"Home","title":"Home","text":"First, we load the data into Julia and form a categorical variable for the treatment in the study, which was the type of lunch served (assigned at the school level).","category":"page"},{"location":"","page":"Home","title":"Home","text":"using CSV\nusing DataFrames\nusing CategoricalArrays\ncog_df = CSV.read(\"data/cognitive.csv\", DataFrame)\n# form categorical variable for treatment\ncog_df.treatment = categorical(cog_df.treatment, levels=[\"control\", \"calorie\", \"meat\", \"milk\"])\nnothing #hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Next we form model matrices with the help of the StatsModels formula syntax:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using StatsModels\nf = @formula(ravens ~ 1 + treatment + year + sex + age_at_time0 +\n                      height + weight + head_circ + ses + mom_read + mom_write + mom_edu)\nmodel_frame = ModelFrame(f, cog_df)\nmodel_mat = ModelMatrix(model_frame).m\nnothing #hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"We form two model matrices. One is low dimensional and includes only the columns that will have associated random effects and the other is higher dimensional and includes the many features whose effects will be regularized. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"X = model_mat[:, 1:2] # Non-penalized, random effect columns (one for intercept, and the other for year)\nG = model_mat[:, 3:end] # High dimensional set of covariates whose effects are regularized\nnothing #hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Finally, we get the cluster (in this case, student) ids and the response, the students' Ravens test scores, and fit the model with the main function from the package, hdmm:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using HighDimMixedModels\nstudent_id = cog_df.id\ny = cog_df.ravens\nfit = hdmm(X, G, y, student_id)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that by default, we fit a model with the SCAD penalty. To apply the LASSO penalty, simply specify penalty = \"lasso\" in the call to fit the model. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"By default, the features that are assigned random slopes are all those that appear as columns in the matrix X, i.e. those whose coefficients in the model are not penalized. In the above code, X just contains a single constant column, so we are fitting a model with just random intercepts. It's possible, however, to include additional columns in X. If you do so, each corresponding feature will receive a random slopes, by default. If you wish to include a feature whose coefficient is not penalized, but do not wish to assign this feature a random slope, then you can specify the argument Z in the call to hdmm to be a matrix whose columns contain only the variables in X that you wish to assign random slopes.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can inspect the model using common extraction functions from StatsBase.jl. For example, to get the residuals and fitted values,","category":"page"},{"location":"","page":"Home","title":"Home","text":"residuals(fit)\nfitted(fit)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that these fitted values and residuals take into account the random effects by incorporating the best prediction of these random effects (BLUPs) for each student into the predictions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To print a table with the names of the selected variables and their estimated coefficients:","category":"page"},{"location":"","page":"Home","title":"Home","text":"coeftable(fit, coefnames(model_frame))","category":"page"},{"location":"","page":"Home","title":"Home","text":"Here, we plot the observed scores and our model's predictions for five different students over time:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Plots\nmask = student_id .== 1\nplot(cog_df.year[mask], cog_df.ravens[mask], seriestype = :scatter, label = \"student 1\", color = 1 )\nplot!(cog_df.year[mask], fitted(fit)[mask], seriestype = :line, color = 1, linestyle = :dash, linewidth = 3, label = \"\")\nfor i in [2,4,5,6]\n    mask = student_id .== i\n    # add student to plot\n    plot!(cog_df.year[mask], cog_df.ravens[mask], seriestype = :scatter, label = \"student $i\", color = i)\n    plot!(cog_df.year[mask], fitted(fit)[mask], seriestype = :line, color = i, linestyle = :dash, linewidth = 3, label = \"\")\nend\nplot!(legend=:outerbottom, legendcolumns=3, xlabel = \"Year\", ylabel = \"Ravens Score\")","category":"page"},{"location":"#Function-Documentation","page":"Home","title":"Function Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [HighDimMixedModels]","category":"page"},{"location":"#HighDimMixedModels.Control","page":"Home","title":"HighDimMixedModels.Control","text":"Algorithm Hyper-parameters\n\ntol :: Convergence tolerance\nseed :: Random seed for cross validation for estimating initial fixed effect parameters using Lasso\ntrace :: Integer. 1 prints no output, 2 prints issues, and 3 prints the objective function values during the algorithm and issues\nmax_iter :: Integer. Maximum number of iterations\nmax_armijo :: Integer. Maximum number of steps in Armijo rule algorithm. If the maximum is reached, algorithm doesn't update current coordinate and proceeds to the next coordinate\nactnum :: Integer between 1 and 5. We will only update all fixed effect parameters every actnum iterations. Otherwise, we update only the parameters in thea current active set.\na₀ :: a₀ in the Armijo step. See Schelldorfer et al. (2010)\nδ :: δ in the Armijo step. See Schelldorfer et al. (2010)\nρ :: ρ in the Armijo step. See Schelldorfer et al. (2010)\nγ :: γ in the Armijo step. See Schelldorfer et al. (2010)\nlower :: Lower bound for the Hessian\nupper :: Upper bound for the Hessian\nvar_int :: Tuple with bounds of interval on which to optimize the variance parameters used in optimize function. See Optim.jl in section \"minimizing a univariate function on a bounded interval\"\ncov_int :: Tuple with bounds of interval on which to optimize the covariance parameters used in optimize function. See Optim.jl in section \"minimizing a univariate function on a bounded interval\"\noptimize_method :: Symbol denoting method for performing the univariate optimization, either :Brent or :GoldenSection\nthres :: If variance or covariance parameter has smaller absolute value than thres, parameter is set to 0\n\n\n\n\n\n","category":"type"},{"location":"#HighDimMixedModels.HDMModel","page":"Home","title":"HighDimMixedModels.HDMModel","text":"Fitted model object \n\n\n\n\n\n","category":"type"},{"location":"#HighDimMixedModels.L_diag_update!-NTuple{9, Any}","page":"Home","title":"HighDimMixedModels.L_diag_update!","text":"Update of coordinate s of L for diagonal covariance structure\n\nARGUMENTS\n\nL :: A vector of parameters which will be updated by the function\ns :: The coordinate of L that is being updated (number between 1 and length(L))\n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.L_ident_update-NTuple{7, Any}","page":"Home","title":"HighDimMixedModels.L_ident_update","text":"Update of L for identity covariance structure\n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.L_sym_update!-NTuple{10, Any}","page":"Home","title":"HighDimMixedModels.L_sym_update!","text":"Update of L for general symmetric positive definite covariance structure ARGUMENTS\n\nL :: A lower triangular matrix of parameters which will be updated by the function\ncoords :: Tuple representing the coordinates of the entry of L that is being updated\n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.armijo!-Tuple{Any, Any, Any, Any, Any, Any, Any, Real, Real, Any, Any, Any, Any, Any, Any}","page":"Home","title":"HighDimMixedModels.armijo!","text":"Armijo Rule\n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.cov_start-NTuple{4, Any}","page":"Home","title":"HighDimMixedModels.cov_start","text":"Finds an initial value for the variance and covariance parameters \n\nARGUMENTS\n\nXGgrp :: Vector of fixed effect design matrices for each group\nygrp :: Vector of vector of responses for each group\nZgrp :: Vector of random effects design matrix for each group\nβ :: Initial iterate for fixed effect parameter vector (computed with Lasso ignoring group structure)\n\nOUTPUT\n\nAssuming β is true fixed effect vector, MLE estimate of scalar L and scalar σ² as tuple (L, σ²)\n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.get_cost","page":"Home","title":"HighDimMixedModels.get_cost","text":"Calculates the objective function\n\n\n\n\n\n","category":"function"},{"location":"#HighDimMixedModels.get_negll-NTuple{4, Any}","page":"Home","title":"HighDimMixedModels.get_negll","text":"Calculates the negative log-likelihod  -l(ϕ̃) = -l(β, θ, σ²) = .5(Ntot*log(2π) + log|V| + (y-xβ)'V⁻¹(y-Xβ)) \n\nARGUMENTS\n\ninvVgrp :: Vector of length the number of groups, each of whose elements is the precision matrix of the responses within a group\nygrp :: Vector of vector of responses for each group\nX :: Vector of fixed effect design matrices for each group\nβ :: Fixed effects\n\nOUTPUT\n\nValue of the negative log-likelihood\n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.get_scad","page":"Home","title":"HighDimMixedModels.get_scad","text":"Calculates the SCAD penalty\n\n\n\n\n\n","category":"function"},{"location":"#HighDimMixedModels.hdmm","page":"Home","title":"HighDimMixedModels.hdmm","text":"Fits penalized linear mixed effect model \n\nARGUMENTS Positional: \n\nX :: Low dimensional design matrix for unpenalized fixed effects (assumed to include column of ones) (REQUIRED)\nG :: High dimensional design matrix for penalized fixed effects (assumed to not include column of ones) (REQUIRE)\ny :: Vector of responses (REQUIRED)\ngrp :: Vector of strings of same length as y assigning each observation to a particular group (REQUIRED)\nZ :: Design matrix for random effects (default is all columns of X)\n\nNOTE: Z is not expected to be given in block diagonal form. It should be a vertical stack of subject design matrices Z₁, Z₂, ...\n\nKeyword:\n\nstandardize :: boolean (default true), whether to standardize design matrices before performing algorithm. \npenalty :: One of \"scad\" (default) or \"lasso\"\nλ :: Positive regularizing penalty (default is 10.0)\nscada :: Extra tuning parameter for the SCAD penalty (default is 3.7, ignored if penalty is \"lasso\"\nwts :: Vector of length number of penalized coefficients. Strength of penalty on covariate j is λ/wⱼ (Default is vector of 1's)\ninit_coef :: Named tuple of form (β, L, σ²) giving initial values for parameters. If unspecified, then inital values for parameters are \n\ncalculated as follows: first, cross-validated LASSO that ignores grouping structure is performed to obtain initial estimates of the  fixed effect parameters. Then, the random effect parameters are initialized as MLEs assuming the LASSO estimates are true fixed effect parameters.\n\nψstr :: One of \"diag\" (default), \"ident\", or \"sym\", specifying covariance structure of random effects \ncontrol :: Struct with fields for hyperparameters of the algorithm \n\nOUTPUT\n\nFitted model\n\n\n\n\n\n","category":"function"},{"location":"#HighDimMixedModels.hessian_diag!-NTuple{5, Any}","page":"Home","title":"HighDimMixedModels.hessian_diag!","text":"Calculates active_set entries of the diagonal of Hessian matrix for fixed effect parameters \n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.invV!-NTuple{4, Any}","page":"Home","title":"HighDimMixedModels.invV!","text":"Updates precision matrices of the responses, by group\n\nARGUMENTS\n\ninvVgrp :: Container for precision matrices of the responses, by group\nZgrp :: Container of random effects design matrices, by group\nL :: Parameters for random effect covariance matrix (can be scalar, vector, or lower triangular matrix)\nσ² :: Variance of error\n\nOUTPUT\n\ninvVgrp :: List of length the number of groups, each of whose elements is the covariance matrix of the responses within a group\n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.scad_dir-NTuple{5, Real}","page":"Home","title":"HighDimMixedModels.scad_dir","text":"Calculates descent direction with SCAD penalty\n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.scad_solution-NTuple{4, Any}","page":"Home","title":"HighDimMixedModels.scad_solution","text":"Gets analytical solution for CGD iterate with SCAD penalty when the Hessian hasn't been truncated \n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.soft_thresh-Tuple{Any, Any}","page":"Home","title":"HighDimMixedModels.soft_thresh","text":"Soft Threshold\n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.special_quad-NTuple{7, Any}","page":"Home","title":"HighDimMixedModels.special_quad","text":"Calculates (y-ỹ)'(invV)X[:,j], where ỹ are the fitted values if we ignored the jth column i.e. XG[:,Not(j)]β[Not(j)] To improve perforamce, we calculate ỹ with the entire dataset  We then split into groups and calculate (y-ỹ)'(invV)*X[:,j] for each group\n\n\n\n\n\n","category":"method"},{"location":"#HighDimMixedModels.σ²update-NTuple{6, Any}","page":"Home","title":"HighDimMixedModels.σ²update","text":"Update of σ²\n\n\n\n\n\n","category":"method"}]
}

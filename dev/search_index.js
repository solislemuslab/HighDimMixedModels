var documenterSearchIndex = {"docs":
[{"location":"lib/internal_methods/","page":"Internal Methods and Types","title":"Internal Methods and Types","text":"Modules = [HighDimMixedModels]\nPublic = false","category":"page"},{"location":"lib/internal_methods/#HighDimMixedModels.L_diag_update!-NTuple{9, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.L_diag_update!","text":"Update of coordinate s of L for diagonal covariance structure\n\nARGUMENTS\n\nL :: A vector of parameters which will be updated by the function\ns :: The coordinate of L that is being updated (number between 1 and length(L))\n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.L_ident_update-NTuple{7, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.L_ident_update","text":"Update of L for identity covariance structure\n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.L_sym_update!-NTuple{10, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.L_sym_update!","text":"Update of L for general symmetric positive definite covariance structure ARGUMENTS\n\nL :: A lower triangular matrix of parameters which will be updated by the function\ncoords :: Tuple representing the coordinates of the entry of L that is being updated\n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.armijo!-Tuple{Any, Any, Any, Any, Any, Any, Any, Real, Real, Any, Any, Any, Any, Any, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.armijo!","text":"Armijo Rule\n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.cov_start-NTuple{4, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.cov_start","text":"Finds an initial value for the variance and covariance parameters \n\nARGUMENTS\n\nXGgrp :: Vector of fixed effect design matrices for each group\nygrp :: Vector of vector of responses for each group\nZgrp :: Vector of random effects design matrix for each group\nβ :: Initial iterate for fixed effect parameter vector (computed with Lasso ignoring group structure)\n\nOUTPUT\n\nAssuming β is true fixed effect vector, MLE estimate of scalar L and scalar σ² as tuple (L, σ²)\n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.get_cost","page":"Internal Methods and Types","title":"HighDimMixedModels.get_cost","text":"Calculates the objective function\n\n\n\n\n\n","category":"function"},{"location":"lib/internal_methods/#HighDimMixedModels.get_negll-NTuple{4, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.get_negll","text":"Calculates the negative log-likelihod  -l(ϕ̃) = -l(β, θ, σ²) = .5(Ntot*log(2π) + log|V| + (y-xβ)'V⁻¹(y-Xβ)) \n\nARGUMENTS\n\ninvVgrp :: Vector of length the number of groups, each of whose elements is the precision matrix of the responses within a group\nygrp :: Vector of vector of responses for each group\nX :: Vector of fixed effect design matrices for each group\nβ :: Fixed effects\n\nOUTPUT\n\nValue of the negative log-likelihood\n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.get_scad","page":"Internal Methods and Types","title":"HighDimMixedModels.get_scad","text":"Calculates the SCAD penalty\n\n\n\n\n\n","category":"function"},{"location":"lib/internal_methods/#HighDimMixedModels.hessian_diag!-NTuple{5, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.hessian_diag!","text":"Calculates active_set entries of the diagonal of Hessian matrix for fixed effect parameters \n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.invV!-NTuple{4, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.invV!","text":"Updates precision matrices of the responses, by group\n\nARGUMENTS\n\ninvVgrp :: Container for precision matrices of the responses, by group\nZgrp :: Container of random effects design matrices, by group\nL :: Parameters for random effect covariance matrix (can be scalar, vector, or lower triangular matrix)\nσ² :: Variance of error\n\nOUTPUT\n\ninvVgrp :: List of length the number of groups, each of whose elements is the covariance matrix of the responses within a group\n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.scad_dir-NTuple{5, Real}","page":"Internal Methods and Types","title":"HighDimMixedModels.scad_dir","text":"Calculates descent direction with SCAD penalty\n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.scad_solution-NTuple{4, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.scad_solution","text":"Gets analytical solution for CGD iterate with SCAD penalty when the Hessian hasn't been truncated \n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.soft_thresh-Tuple{Any, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.soft_thresh","text":"Soft Threshold\n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.special_quad-NTuple{7, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.special_quad","text":"Calculates (y-ỹ)'(invV)X[:,j], where ỹ are the fitted values if we ignored the jth column i.e. XG[:,Not(j)]β[Not(j)] To improve perforamce, we calculate ỹ with the entire dataset  We then split into groups and calculate (y-ỹ)'(invV)*X[:,j] for each group\n\n\n\n\n\n","category":"method"},{"location":"lib/internal_methods/#HighDimMixedModels.σ²update-NTuple{6, Any}","page":"Internal Methods and Types","title":"HighDimMixedModels.σ²update","text":"Update of σ²\n\n\n\n\n\n","category":"method"},{"location":"lib/public_methods/","page":"Public Methods and Types","title":"Public Methods and Types","text":"Modules = [HighDimMixedModels]\nPrivate = false","category":"page"},{"location":"lib/public_methods/#HighDimMixedModels.Control","page":"Public Methods and Types","title":"HighDimMixedModels.Control","text":"Control  Provides hyperparameters for the coordinate descent algorithm.\n\nFields\n\ntol: Small positive number, default is 1e-4, providing convergence tolerance\nseed :: Random seed, default 770. Note that the only randomness in the algorithm is during the initialization of fixed effect parameters (for the data splits in the cross validation)\ntrace :: Integer, default 2. 1 prints no output, 2 prints issues, and 3 prints issues and the objective function values during the algorithm \nmax_iter :: Integer, default 1000, giving maximum number of iterations in the coordinate gradient descent.\nmax_armijo :: Integer, default 20, giving the maximum number of steps in the Armijo algorithm. If the maximum is reached, algorithm doesn't update current coordinate and proceeds to the next coordinate\nactnum :: Integer, default 5. We will only update all of the fixed effect parameters every `actnum` iterations. Otherwise, we update only the parameters in the current active set.\na₀ :: a₀ in the Armijo step, default 1.0. See Schelldorfer et al. (2010) for details about this and the next five fields.\nδ :: δ in the Armijo step, default 0.1. \nρ :: ρ in the Armijo step, default 0.001. \nγ :: γ in the Armijo step, default 0.0. \nlower :: Lower bound for the Hessian, default 1e-6. \nupper :: Upper bound for the Hessian, default 1e8.\nvar_int :: Tuple with bounds of interval on which to optimize when updating a diagonal entry of L, default (0, 100). See Optim.jl in section \"minimizing a univariate function on a bounded interval\"\ncov_int :: Tuple with bounds of interval on which to optimize the when updating a non-diagonal entry of L, default (-50, 50). See Optim.jl in section \"minimizing a univariate function on a bounded interval\"\noptimize_method :: Symbol denoting method for performing the univariate optimization, either :Brent or :GoldenSection, default is :Brent\nthres :: If an update of an entry of L or of σ² would be smaller in absolute value than thres, the parameter is set to 0\n\n\n\n\n\n","category":"type"},{"location":"lib/public_methods/#HighDimMixedModels.HDMModel","page":"Public Methods and Types","title":"HighDimMixedModels.HDMModel","text":"Stores the results of a fitted model\n\n\n\n\n\n","category":"type"},{"location":"lib/public_methods/#HighDimMixedModels.hdmm","page":"Public Methods and Types","title":"HighDimMixedModels.hdmm","text":"hdmm(X::Matrix{<:Real}, G::Matrix{<:Real}, y::Vector{<:Real}, \n    grp::Vector{<:Union{String, Int64}}, Z::Matrix{<:Real}=X;\n    standardize=true, penalty::String=\"scad\", λ::Real=10.0, scada::Real=3.7, \n    wts::Union{Vector, Nothing}=nothing, init_coef::Union{Vector,Nothing}=nothing, \n    ψstr::String=\"diag\", control::Control=Control())\n\nMain function for the package. Fits a penalized linear mixed effect model using the coordinate gradient descent algorithm.\n\nArguments\n\nPositional: \n\nX: Low dimensional (N by q) design matrix for unpenalized fixed effects (first column must be 1's to fit intercept) \nG: High dimensional (N by p) design matrix for penalized fixed effects (should not include column of 1's) \ny: Response vector\ngrp: Vector of either strings or integers with group assignments of each observation \nZ: Design matrix (N by m) for random effects, defaults to equal X\n\nKeyword:\n\npenalty: String, one of \"scad\" (default) or \"lasso\"\nλ: Positive number, default=10, providing the regularization parameter for the penalty\nscada: Positive number, default=3.7, providing the extra tuning parameter for the SCAD penalty (ignored if penalty is \"lasso\")\nstandardize: Boolean, deault=true, whether to standardize the columns of all design matrices before performing coordinate descent. Note that the value of λ should be chosen accordingly. Results will always be returned on the original scale\nwts: Vector of length p, default is vector of 1's. The penalty on covariate j will be λ/wⱼ, so this argument is useful if you want to penalize some covariates more than others. \nψstr: String, one of \"diag\" (default), \"ident\", or \"sym\", specifying covariance structure of the random effects \ninit_coef: Named tuple of form (β, L, σ²), where \nβ is a vector of length p + q providing an initial estimate of the fixed effect coefficients\nL is the Cholesky factor of the random effect covariance matrix, and is represented as \na scalar if ψstr=\"ident\"\na vector of length m if ψstr=\"diag\"\na lower triangular matrix of size m by m if ψstr=\"sym\"\nσ² is a scalar providing an initial estimate of the noise variance\nSee below for how these inital parameter estimates are calculated if not provided.\ncontrol: Custom struct with fields for hyperparameters of the algorithm, defaults are in documentation of Control struct\n\nIf the init_coef argument is not specified, we perform the following steps to obtain the initial parameters to feed to the coordinate descent algorithm:\n\nFirst, a LASSO (with λ chosen using cross validation) that ignores random effects is performed to estimate the fixed effect parameters. \nThen, L, assumed for the moment to be a scalar, and σ² are estimated to maximize the likelihood given the estimated fixed effect parameters.\nFinally, if ψstr is \"diag\" or \"sym\", the scalar L is converted to a vector or matrix by repeating the scalar or filling the diagonal of a matrix with the scalar, respectively.\n\nReturns\n\nFitted model object of type HDMModel with fields for all relevant information about the model fit.\n\n\n\n\n\n","category":"function"},{"location":"lib/public_methods/#StatsAPI.aic-Tuple{HDMModel}","page":"Public Methods and Types","title":"StatsAPI.aic","text":"aic(fit::HDMModel)\n\nThe Akaike Information Criterion is equal to the deviance plus 2 times the number of parameters in the model\n\n\n\n\n\n","category":"method"},{"location":"lib/public_methods/#StatsAPI.bic-Tuple{HDMModel}","page":"Public Methods and Types","title":"StatsAPI.bic","text":"bic(fit::HDMModel)\n\nThe Bayesian Information Criterion is equal to the deviance plus the log of the number of observations times the number of parameters in the model\n\n\n\n\n\n","category":"method"},{"location":"lib/public_methods/#StatsAPI.coef-Tuple{HDMModel}","page":"Public Methods and Types","title":"StatsAPI.coef","text":"coef(fit::HDMMModel)\n\nRetrieves all estimated fixed effect coefficients\n\n\n\n\n\n","category":"method"},{"location":"lib/public_methods/#StatsAPI.coeftable","page":"Public Methods and Types","title":"StatsAPI.coeftable","text":"coeftable(fit::HDMModel, names::Vector{String}=string.(1:length(fit.fixef)))\n\nReturns a table of the selected coefficients, i.e. those not set to 0, from the model.\n\nArguments\n\nfit::HDMModel: A fitted model.\nnames::Vector{String}: Names of the all the coefficients in the model (not just those selected), defaults to integer names \n\nReturns\n\nA StatsBase.CoefTable object.\n\n\n\n\n\n","category":"function"},{"location":"lib/public_methods/#StatsAPI.deviance-Tuple{HDMModel}","page":"Public Methods and Types","title":"StatsAPI.deviance","text":"deviance(fit::HDMModel)\n\n-2*loglikelihood of the model at the estimated parameters\n\n\n\n\n\n","category":"method"},{"location":"lib/public_methods/#StatsAPI.fitted-Tuple{HDMModel}","page":"Public Methods and Types","title":"StatsAPI.fitted","text":"fitted(fit::HDMModel)\n\nAccounts for the random effects in generating predictions\n\n\n\n\n\n","category":"method"},{"location":"lib/public_methods/#StatsAPI.loglikelihood-Tuple{HDMModel}","page":"Public Methods and Types","title":"StatsAPI.loglikelihood","text":"loglikelihood(fit::HDMModel)\n\nLog-likelihood of the model at the estimated parameters\n\n\n\n\n\n","category":"method"},{"location":"lib/public_methods/#StatsAPI.nobs-Tuple{HDMModel}","page":"Public Methods and Types","title":"StatsAPI.nobs","text":"nobs(fit::HDMModel)\n\nNumber of observations used in fitting the model\n\n\n\n\n\n","category":"method"},{"location":"lib/public_methods/#StatsAPI.residuals-Tuple{HDMModel}","page":"Public Methods and Types","title":"StatsAPI.residuals","text":"residuals(fit::HDMModel)\n\nAccounts for the random effects in generating predictions\n\n\n\n\n\n","category":"method"},{"location":"man/example/#Example","page":"Example","title":"Example","text":"","category":"section"},{"location":"man/example/#Load-dataset","page":"Example","title":"Load dataset","text":"","category":"section"},{"location":"man/example/","page":"Example","title":"Example","text":"The cognitive dataset contains data from a study of the effect of an intervention in school lunches among schools in Kenya, accessed via the R package splmm. The data is longitudinal with measurements of students' performance on various tests taken at different points in time. We will fit a model with random intercepts and random growth slopes for each student. Note that while this is a low-dimensional example (p  n), the algorithm that this package implements was designed and tested with the high dimensional use-case (p  n) in mind.","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"First, we load the data into Julia and form a categorical variable for the treatment in the study, which was the type of lunch served (assigned at the school level).","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"using CSV\nusing DataFrames\nusing CategoricalArrays\ncog_df = CSV.read(\"../data/cognitive.csv\", DataFrame)\n# form categorical variable for treatment\ncog_df.treatment = categorical(cog_df.treatment, levels=[\"control\", \"calorie\", \"meat\", \"milk\"])\nnothing # hide","category":"page"},{"location":"man/example/#Extract-model-matrices,-cluster-ids,-and-response-vector","page":"Example","title":"Extract model matrices, cluster ids, and response vector","text":"","category":"section"},{"location":"man/example/","page":"Example","title":"Example","text":"Next we form model matrices with the help of the StatsModels formula syntax:","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"using StatsModels\nf = @formula(ravens ~ 1 + year + treatment + sex + age_at_time0 +\n                      height + weight + head_circ + ses + mom_read + mom_write + mom_edu)\nmodel_frame = ModelFrame(f, cog_df)\nmodel_mat = ModelMatrix(model_frame).m\nnothing # hide","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"We form two model matrices. One is low dimensional and includes features we do not wish to penalize, and the other is higher dimensional and includes the many features whose effects will be regularized. ","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"X = model_mat[:, 1:2] # Non-penalized, random effect columns (one for intercept, and the other for year)\nG = model_mat[:, 3:end] # High dimensional set of covariates whose effects are regularized\nnothing # hide","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"Finally, we get the cluster (in this case, student) ids and the response, the students' Ravens test scores. ","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"using HighDimMixedModels\nstudent_id = cog_df.id\ny = cog_df.ravens\nnothing # hide","category":"page"},{"location":"man/example/#Fitting-model","page":"Example","title":"Fitting model","text":"","category":"section"},{"location":"man/example/","page":"Example","title":"Example","text":"The main function in the package is hdmm(), which requires the two design matrices, the response, and the group id as required positional arguments, and returns the fitted model:","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"using HighDimMixedModels\nfit = hdmm(X, G, y, student_id)","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"The function has a number of keyword arguments that can be specified to modify the defaults–see the documentation. For example, by default, we fit a model with the SCAD penalty, which produces less bias. To apply the LASSO penalty, specify penalty = \"lasso\" in the call. Also note that the default value of lambda (the hyperparameter that controls the degree of penalization) is 10. Since the default (unless standardize = false) is to standardize the design matrices before running the algorithm, this is how much the coefficients of the standardized predictors are penalized. In practice, you can and should try fitting the model for several different choices of lambda and choose the fit that leads to the lowest fit.BIC.","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"By default, the features that are assigned random slopes are all those that appear as columns in the matrix X, i.e. those features whose coefficients are not penalized. If you wish to include a feature whose coefficient is not penalized, but do not wish to assign this feature a random slope, then you can specify the argument Z in the call to hdmm to be a matrix whose columns contain only the variables in X that you wish to assign random slopes.","category":"page"},{"location":"man/example/#Inspecting-model","page":"Example","title":"Inspecting model","text":"","category":"section"},{"location":"man/example/","page":"Example","title":"Example","text":"The object fit which is returned by hdmm() is a struct with fields providing all relevant information about the model fit. These can be accessed using the dot notation, e.g. fit.fixef to retrieve all the fixed effect estimates (including those set to 0) and fit.log_like to get the log likelihood at the estimates. To print all the fields stored in the object, you can type fit. followed by the tab key.","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"We also implement several common extraction functions from StatsBase.jl, such as residuals(fit) and fitted(fit). Note that these fitted values and residuals take into account the random effects by incorporating the best prediction of these random effects (BLUPs) for each student into the predictions. ","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"To print a table with only the selected coefficients (i.e. those that are not set to 0), use the function coeftable(). The names of these variables will appear alongside their estimates if you pass them as a second argument:","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"coeftable(fit, coefnames(model_frame))","category":"page"},{"location":"man/example/#Plotting-model","page":"Example","title":"Plotting model","text":"","category":"section"},{"location":"man/example/","page":"Example","title":"Example","text":"Here, we show how to plot the observed scores and our model's predictions for five different students over time:","category":"page"},{"location":"man/example/","page":"Example","title":"Example","text":"using Plots\nmask = student_id .== 1\nplot(cog_df.year[mask], cog_df.ravens[mask], seriestype = :scatter, label = \"student 1\", color = 1 )\nplot!(cog_df.year[mask], fitted(fit)[mask], seriestype = :line, color = 1, linestyle = :dash, linewidth = 3, label = \"\")\nfor i in [2,4,5,6]\n    mask = student_id .== i\n    # add student to plot\n    plot!(cog_df.year[mask], cog_df.ravens[mask], seriestype = :scatter, label = \"student $i\", color = i)\n    plot!(cog_df.year[mask], fitted(fit)[mask], seriestype = :line, color = i, linestyle = :dash, linewidth = 3, label = \"\")\nend\nplot!(legend=:outerbottom, legendcolumns=3, xlabel = \"Year\", ylabel = \"Ravens Score\")","category":"page"},{"location":"#HighDimMixedModels.jl","page":"Home","title":"HighDimMixedModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"HighDimMixedModels.jl is a package for fitting regularized linear mixed-effect models to high dimensional, clustered data. It is a Julia implementation of the estimation approach in","category":"page"},{"location":"","page":"Home","title":"Home","text":"Schelldorfer, J., Bühlmann, P., & DE GEER, S. V. (2011). Estimation for high‐dimensional linear mixed‐effects models using ℓ1‐penalization. Scandinavian Journal of Statistics, 38(2), 197-214.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Two options for penalties are provided, the original LASSO and the smoothly clipped absolute deviation (SCAD) penalty described in","category":"page"},{"location":"","page":"Home","title":"Home","text":"Ghosh, A., & Thoresen, M. (2018). Non-concave penalization in linear mixed-effect models and regularized selection of fixed effects. AStA Advances in Statistical Analysis, 102, 179-210.","category":"page"},{"location":"man/installation/#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"man/installation/#Installation-of-Julia","page":"Installation","title":"Installation of Julia","text":"","category":"section"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"Julia is a high-level and interactive programming language (like R or Matlab), but it is also high-performance (like C). To install Julia, follow instructions here. For a quick & basic tutorial on Julia, see learn x in y minutes.","category":"page"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"Editors:","category":"page"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"Visual Studio Code provides an editor and an integrated development environment (IDE) for Julia: highly recommended!\nYou can also run Julia within a Jupyter notebook (formerly IPython notebook).","category":"page"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"IMPORTANT: Julia code is just-in-time compiled. This means that the first time you run a function, it will be compiled at that moment. So, please be patient! Future calls to the function will be much much faster. Trying out toy examples for the first calls is a good idea.","category":"page"},{"location":"man/installation/#Installation-of-the-package","page":"Installation","title":"Installation of the package","text":"","category":"section"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"To install HighDimMixedModels, type in the Julia REPL","category":"page"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"]\nadd https://github.com/solislemuslab/HighDimMixedModels.jl.git","category":"page"},{"location":"man/installation/","page":"Installation","title":"Installation","text":"The installation can take a few minutes, be patient. The package has dependencies such as Optim.jl and Lasso.jl (see the Project.toml file for the full list), but everything is installed automatically. ","category":"page"}]
}
